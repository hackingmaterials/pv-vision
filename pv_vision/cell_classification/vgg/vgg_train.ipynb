{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imutils import paths\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 50\n",
    "init_lr = 1e-3\n",
    "batchsize = 64\n",
    "class_num = 2\n",
    "norm_size = 64\n",
    "depth = 3\n",
    "\n",
    "label_dir = {\n",
    "    \"SN\": 0,\n",
    "    \"PN\": 0,\n",
    "    \"SC\": 1,\n",
    "    \"PC\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(norm_size,norm_size,depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "conv_base.trainable = False\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(class_num, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "#Loading the data\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "imagePaths = sorted(list(paths.list_images(\"../Images/Training_Set/\")))#args[\"dataset\"])))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (norm_size, norm_size))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "\n",
    "    label_str = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "    labels.append(label_dir[label_str])\n",
    "\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# partition the data into 80% training_total and 20% testing\n",
    "#partition the training_total data into 75% training data and 25% validation data \n",
    "(trainX_t, testX, trainY_t, testY) = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "(trainX, valX, trainY, valY) = train_test_split(trainX_t, trainY_t, test_size=0.25, random_state=42)\n",
    "\n",
    "#labels = to_categorical(labels, num_classes=CLASS_NUM)\n",
    "# convert the labels from integers to vectors\n",
    "trainY = to_categorical(trainY, num_classes=class_num)\n",
    "valY = to_categorical(valY, num_classes=class_num)\n",
    "testY = to_categorical(testY, num_classes=class_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, \n",
    "                                   fill_mode=\"nearest\")\n",
    "train_generator = train_datagen.flow(trainX, trainY, batch_size=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator()\n",
    "val_generator = val_datagen.flow(valX, valY, batch_size=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=init_lr, decay=init_lr/epoch_num)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "WARNING:tensorflow:From <ipython-input-20-376d0507598f>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 28 steps, validate for 9 steps\n",
      "Epoch 1/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.6297 - accuracy: 0.6611\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74826, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 26s 931ms/step - loss: 0.6260 - accuracy: 0.6643 - val_loss: 0.5301 - val_accuracy: 0.7483\n",
      "Epoch 2/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.4869 - accuracy: 0.7656\n",
      "Epoch 00002: val_accuracy improved from 0.74826 to 0.77344, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 26s 919ms/step - loss: 0.4856 - accuracy: 0.7662 - val_loss: 0.4883 - val_accuracy: 0.7734\n",
      "Epoch 3/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.4439 - accuracy: 0.7890\n",
      "Epoch 00003: val_accuracy did not improve from 0.77344\n",
      "28/28 [==============================] - 32s 1s/step - loss: 0.4443 - accuracy: 0.7884 - val_loss: 0.4816 - val_accuracy: 0.7717\n",
      "Epoch 4/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.4482 - accuracy: 0.7855\n",
      "Epoch 00004: val_accuracy improved from 0.77344 to 0.79253, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 28s 989ms/step - loss: 0.4460 - accuracy: 0.7873 - val_loss: 0.4707 - val_accuracy: 0.7925\n",
      "Epoch 5/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.4303 - accuracy: 0.8021\n",
      "Epoch 00005: val_accuracy improved from 0.79253 to 0.79514, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 28s 994ms/step - loss: 0.4303 - accuracy: 0.8022 - val_loss: 0.4580 - val_accuracy: 0.7951\n",
      "Epoch 6/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.4200 - accuracy: 0.7963\n",
      "Epoch 00006: val_accuracy did not improve from 0.79514\n",
      "28/28 [==============================] - 28s 1s/step - loss: 0.4228 - accuracy: 0.7952 - val_loss: 0.4598 - val_accuracy: 0.7743\n",
      "Epoch 7/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.4213 - accuracy: 0.7995\n",
      "Epoch 00007: val_accuracy improved from 0.79514 to 0.80729, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 28s 990ms/step - loss: 0.4229 - accuracy: 0.7980 - val_loss: 0.4371 - val_accuracy: 0.8073\n",
      "Epoch 8/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.4036 - accuracy: 0.8182\n",
      "Epoch 00008: val_accuracy improved from 0.80729 to 0.80903, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 28s 1s/step - loss: 0.4042 - accuracy: 0.8174 - val_loss: 0.4341 - val_accuracy: 0.8090\n",
      "Epoch 9/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.4026 - accuracy: 0.8071\n",
      "Epoch 00009: val_accuracy improved from 0.80903 to 0.81684, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 28s 984ms/step - loss: 0.4023 - accuracy: 0.8073 - val_loss: 0.4284 - val_accuracy: 0.8168\n",
      "Epoch 10/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.4092 - accuracy: 0.8225\n",
      "Epoch 00010: val_accuracy did not improve from 0.81684\n",
      "28/28 [==============================] - 28s 1s/step - loss: 0.4082 - accuracy: 0.8239 - val_loss: 0.4283 - val_accuracy: 0.8142\n",
      "Epoch 11/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3889 - accuracy: 0.8202\n",
      "Epoch 00011: val_accuracy did not improve from 0.81684\n",
      "28/28 [==============================] - 28s 987ms/step - loss: 0.3889 - accuracy: 0.8210 - val_loss: 0.4276 - val_accuracy: 0.8030\n",
      "Epoch 12/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3795 - accuracy: 0.8310\n",
      "Epoch 00012: val_accuracy improved from 0.81684 to 0.82552, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 28s 995ms/step - loss: 0.3812 - accuracy: 0.8295 - val_loss: 0.4163 - val_accuracy: 0.8255\n",
      "Epoch 13/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3791 - accuracy: 0.8339\n",
      "Epoch 00013: val_accuracy did not improve from 0.82552\n",
      "28/28 [==============================] - 28s 992ms/step - loss: 0.3784 - accuracy: 0.8323 - val_loss: 0.4140 - val_accuracy: 0.8212\n",
      "Epoch 14/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3907 - accuracy: 0.8152\n",
      "Epoch 00014: val_accuracy did not improve from 0.82552\n",
      "28/28 [==============================] - 28s 992ms/step - loss: 0.3908 - accuracy: 0.8151 - val_loss: 0.4163 - val_accuracy: 0.8168\n",
      "Epoch 15/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3749 - accuracy: 0.8307\n",
      "Epoch 00015: val_accuracy did not improve from 0.82552\n",
      "28/28 [==============================] - 28s 984ms/step - loss: 0.3742 - accuracy: 0.8315 - val_loss: 0.4394 - val_accuracy: 0.7977\n",
      "Epoch 16/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3828 - accuracy: 0.8255\n",
      "Epoch 00016: val_accuracy did not improve from 0.82552\n",
      "28/28 [==============================] - 28s 1s/step - loss: 0.3832 - accuracy: 0.8247 - val_loss: 0.4218 - val_accuracy: 0.8073\n",
      "Epoch 17/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3734 - accuracy: 0.8325\n",
      "Epoch 00017: val_accuracy did not improve from 0.82552\n",
      "28/28 [==============================] - 28s 999ms/step - loss: 0.3753 - accuracy: 0.8309 - val_loss: 0.4134 - val_accuracy: 0.8220\n",
      "Epoch 18/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3670 - accuracy: 0.8400\n",
      "Epoch 00018: val_accuracy did not improve from 0.82552\n",
      "28/28 [==============================] - 28s 989ms/step - loss: 0.3666 - accuracy: 0.8402 - val_loss: 0.4022 - val_accuracy: 0.8151\n",
      "Epoch 19/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3636 - accuracy: 0.8330\n",
      "Epoch 00019: val_accuracy did not improve from 0.82552\n",
      "28/28 [==============================] - 27s 981ms/step - loss: 0.3644 - accuracy: 0.8343 - val_loss: 0.4258 - val_accuracy: 0.8160\n",
      "Epoch 20/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3710 - accuracy: 0.8287\n",
      "Epoch 00020: val_accuracy improved from 0.82552 to 0.82899, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 27s 976ms/step - loss: 0.3682 - accuracy: 0.8317 - val_loss: 0.3955 - val_accuracy: 0.8290\n",
      "Epoch 21/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3507 - accuracy: 0.8471\n",
      "Epoch 00021: val_accuracy did not improve from 0.82899\n",
      "28/28 [==============================] - 27s 978ms/step - loss: 0.3557 - accuracy: 0.8430 - val_loss: 0.3949 - val_accuracy: 0.8290\n",
      "Epoch 22/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3502 - accuracy: 0.8371\n",
      "Epoch 00022: val_accuracy improved from 0.82899 to 0.83594, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 27s 981ms/step - loss: 0.3472 - accuracy: 0.8382 - val_loss: 0.3863 - val_accuracy: 0.8359\n",
      "Epoch 23/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3558 - accuracy: 0.8444\n",
      "Epoch 00023: val_accuracy improved from 0.83594 to 0.84201, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 27s 980ms/step - loss: 0.3625 - accuracy: 0.8402 - val_loss: 0.3934 - val_accuracy: 0.8420\n",
      "Epoch 24/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3476 - accuracy: 0.8488\n",
      "Epoch 00024: val_accuracy did not improve from 0.84201\n",
      "28/28 [==============================] - 28s 984ms/step - loss: 0.3487 - accuracy: 0.8478 - val_loss: 0.3968 - val_accuracy: 0.8420\n",
      "Epoch 25/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3415 - accuracy: 0.8526\n",
      "Epoch 00025: val_accuracy improved from 0.84201 to 0.84896, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 27s 979ms/step - loss: 0.3415 - accuracy: 0.8526 - val_loss: 0.3851 - val_accuracy: 0.8490\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3476 - accuracy: 0.8435\n",
      "Epoch 00026: val_accuracy did not improve from 0.84896\n",
      "28/28 [==============================] - 27s 968ms/step - loss: 0.3437 - accuracy: 0.8461 - val_loss: 0.4173 - val_accuracy: 0.8229\n",
      "Epoch 27/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3355 - accuracy: 0.8546\n",
      "Epoch 00027: val_accuracy did not improve from 0.84896\n",
      "28/28 [==============================] - 27s 971ms/step - loss: 0.3363 - accuracy: 0.8534 - val_loss: 0.3812 - val_accuracy: 0.8429\n",
      "Epoch 28/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3369 - accuracy: 0.8514\n",
      "Epoch 00028: val_accuracy did not improve from 0.84896\n",
      "28/28 [==============================] - 27s 959ms/step - loss: 0.3362 - accuracy: 0.8514 - val_loss: 0.3934 - val_accuracy: 0.8359\n",
      "Epoch 29/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3382 - accuracy: 0.8520\n",
      "Epoch 00029: val_accuracy did not improve from 0.84896\n",
      "28/28 [==============================] - 27s 962ms/step - loss: 0.3405 - accuracy: 0.8528 - val_loss: 0.4000 - val_accuracy: 0.8464\n",
      "Epoch 30/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3336 - accuracy: 0.8552\n",
      "Epoch 00030: val_accuracy did not improve from 0.84896\n",
      "28/28 [==============================] - 27s 952ms/step - loss: 0.3366 - accuracy: 0.8537 - val_loss: 0.4390 - val_accuracy: 0.7830\n",
      "Epoch 31/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3347 - accuracy: 0.8523\n",
      "Epoch 00031: val_accuracy did not improve from 0.84896\n",
      "28/28 [==============================] - 27s 956ms/step - loss: 0.3331 - accuracy: 0.8528 - val_loss: 0.3752 - val_accuracy: 0.8455\n",
      "Epoch 32/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3431 - accuracy: 0.8485\n",
      "Epoch 00032: val_accuracy did not improve from 0.84896\n",
      "28/28 [==============================] - 27s 968ms/step - loss: 0.3420 - accuracy: 0.8492 - val_loss: 0.3840 - val_accuracy: 0.8464\n",
      "Epoch 33/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3239 - accuracy: 0.8628\n",
      "Epoch 00033: val_accuracy did not improve from 0.84896\n",
      "28/28 [==============================] - 27s 970ms/step - loss: 0.3257 - accuracy: 0.8613 - val_loss: 0.3727 - val_accuracy: 0.8429\n",
      "Epoch 34/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3374 - accuracy: 0.8529\n",
      "Epoch 00034: val_accuracy improved from 0.84896 to 0.85069, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 27s 981ms/step - loss: 0.3391 - accuracy: 0.8514 - val_loss: 0.3710 - val_accuracy: 0.8507\n",
      "Epoch 35/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3301 - accuracy: 0.8543\n",
      "Epoch 00035: val_accuracy did not improve from 0.85069\n",
      "28/28 [==============================] - 27s 956ms/step - loss: 0.3302 - accuracy: 0.8537 - val_loss: 0.3726 - val_accuracy: 0.8411\n",
      "Epoch 36/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3338 - accuracy: 0.8471\n",
      "Epoch 00036: val_accuracy did not improve from 0.85069\n",
      "28/28 [==============================] - 27s 952ms/step - loss: 0.3372 - accuracy: 0.8458 - val_loss: 0.3788 - val_accuracy: 0.8368\n",
      "Epoch 37/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3425 - accuracy: 0.8465\n",
      "Epoch 00037: val_accuracy improved from 0.85069 to 0.85330, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 27s 958ms/step - loss: 0.3387 - accuracy: 0.8503 - val_loss: 0.3657 - val_accuracy: 0.8533\n",
      "Epoch 38/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3260 - accuracy: 0.8573\n",
      "Epoch 00038: val_accuracy did not improve from 0.85330\n",
      "28/28 [==============================] - 27s 956ms/step - loss: 0.3247 - accuracy: 0.8571 - val_loss: 0.3762 - val_accuracy: 0.8524\n",
      "Epoch 39/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3184 - accuracy: 0.8628\n",
      "Epoch 00039: val_accuracy did not improve from 0.85330\n",
      "28/28 [==============================] - 27s 953ms/step - loss: 0.3207 - accuracy: 0.8624 - val_loss: 0.4230 - val_accuracy: 0.8047\n",
      "Epoch 40/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3305 - accuracy: 0.8573\n",
      "Epoch 00040: val_accuracy did not improve from 0.85330\n",
      "28/28 [==============================] - 27s 949ms/step - loss: 0.3282 - accuracy: 0.8571 - val_loss: 0.3755 - val_accuracy: 0.8394\n",
      "Epoch 41/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3355 - accuracy: 0.8567\n",
      "Epoch 00041: val_accuracy did not improve from 0.85330\n",
      "28/28 [==============================] - 27s 954ms/step - loss: 0.3350 - accuracy: 0.8571 - val_loss: 0.3847 - val_accuracy: 0.8351\n",
      "Epoch 42/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3162 - accuracy: 0.8634\n",
      "Epoch 00042: val_accuracy did not improve from 0.85330\n",
      "28/28 [==============================] - 26s 938ms/step - loss: 0.3190 - accuracy: 0.8630 - val_loss: 0.4297 - val_accuracy: 0.7873\n",
      "Epoch 43/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3155 - accuracy: 0.8683\n",
      "Epoch 00043: val_accuracy did not improve from 0.85330\n",
      "28/28 [==============================] - 27s 958ms/step - loss: 0.3121 - accuracy: 0.8697 - val_loss: 0.3615 - val_accuracy: 0.8490\n",
      "Epoch 44/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3289 - accuracy: 0.8559\n",
      "Epoch 00044: val_accuracy improved from 0.85330 to 0.85503, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 27s 958ms/step - loss: 0.3319 - accuracy: 0.8541 - val_loss: 0.3587 - val_accuracy: 0.8550\n",
      "Epoch 45/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3099 - accuracy: 0.8643\n",
      "Epoch 00045: val_accuracy did not improve from 0.85503\n",
      "28/28 [==============================] - 27s 949ms/step - loss: 0.3155 - accuracy: 0.8618 - val_loss: 0.3759 - val_accuracy: 0.8542\n",
      "Epoch 46/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3106 - accuracy: 0.8602\n",
      "Epoch 00046: val_accuracy did not improve from 0.85503\n",
      "28/28 [==============================] - 27s 947ms/step - loss: 0.3101 - accuracy: 0.8596 - val_loss: 0.3655 - val_accuracy: 0.8550\n",
      "Epoch 47/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3291 - accuracy: 0.8468\n",
      "Epoch 00047: val_accuracy did not improve from 0.85503\n",
      "28/28 [==============================] - 27s 950ms/step - loss: 0.3271 - accuracy: 0.8492 - val_loss: 0.3582 - val_accuracy: 0.8524\n",
      "Epoch 48/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3073 - accuracy: 0.8681\n",
      "Epoch 00048: val_accuracy improved from 0.85503 to 0.85677, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 27s 952ms/step - loss: 0.3055 - accuracy: 0.8689 - val_loss: 0.3535 - val_accuracy: 0.8568\n",
      "Epoch 49/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3107 - accuracy: 0.8663\n",
      "Epoch 00049: val_accuracy did not improve from 0.85677\n",
      "28/28 [==============================] - 27s 962ms/step - loss: 0.3118 - accuracy: 0.8649 - val_loss: 0.3730 - val_accuracy: 0.8446\n",
      "Epoch 50/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3068 - accuracy: 0.8643\n",
      "Epoch 00050: val_accuracy did not improve from 0.85677\n",
      "28/28 [==============================] - 27s 951ms/step - loss: 0.3057 - accuracy: 0.8655 - val_loss: 0.3745 - val_accuracy: 0.8464\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001) #automatically alter the learning rate\n",
    "checkpoint = ModelCheckpoint(filepath=\"0422_binary_test1.h5\", monitor='val_accuracy', \n",
    "                             verbose=1, save_best_only=True, mode='max', period=1)\n",
    "H = model.fit_generator(train_generator, steps_per_epoch=len(trainX)//batchsize,\n",
    "              validation_data=val_generator, validation_steps=len(valX)//batchsize,\n",
    "              epochs=epoch_num, verbose=1, callbacks=[checkpoint,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 28 steps, validate for 9 steps\n",
      "Epoch 1/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3077 - accuracy: 0.8657\n",
      "Epoch 00001: val_accuracy did not improve from 0.85677\n",
      "28/28 [==============================] - 25s 888ms/step - loss: 0.3066 - accuracy: 0.8661 - val_loss: 0.3807 - val_accuracy: 0.8420\n",
      "Epoch 2/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2905 - accuracy: 0.8719\n",
      "Epoch 00002: val_accuracy did not improve from 0.85677\n",
      "28/28 [==============================] - 25s 903ms/step - loss: 0.2938 - accuracy: 0.8700 - val_loss: 0.4087 - val_accuracy: 0.8229\n",
      "Epoch 3/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3356 - accuracy: 0.8543\n",
      "Epoch 00003: val_accuracy did not improve from 0.85677\n",
      "28/28 [==============================] - 26s 918ms/step - loss: 0.3311 - accuracy: 0.8576 - val_loss: 0.3956 - val_accuracy: 0.8429\n",
      "Epoch 4/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2947 - accuracy: 0.8719\n",
      "Epoch 00004: val_accuracy did not improve from 0.85677\n",
      "28/28 [==============================] - 26s 913ms/step - loss: 0.2947 - accuracy: 0.8717 - val_loss: 0.3626 - val_accuracy: 0.8542\n",
      "Epoch 5/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3019 - accuracy: 0.8724\n",
      "Epoch 00005: val_accuracy improved from 0.85677 to 0.86024, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 26s 938ms/step - loss: 0.3018 - accuracy: 0.8714 - val_loss: 0.3551 - val_accuracy: 0.8602\n",
      "Epoch 6/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3112 - accuracy: 0.8669\n",
      "Epoch 00006: val_accuracy did not improve from 0.86024\n",
      "28/28 [==============================] - 26s 934ms/step - loss: 0.3113 - accuracy: 0.8663 - val_loss: 0.4073 - val_accuracy: 0.8220\n",
      "Epoch 7/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3059 - accuracy: 0.8631\n",
      "Epoch 00007: val_accuracy did not improve from 0.86024\n",
      "28/28 [==============================] - 26s 929ms/step - loss: 0.3038 - accuracy: 0.8647 - val_loss: 0.3496 - val_accuracy: 0.8559\n",
      "Epoch 8/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3013 - accuracy: 0.8713\n",
      "Epoch 00008: val_accuracy did not improve from 0.86024\n",
      "28/28 [==============================] - 26s 925ms/step - loss: 0.3037 - accuracy: 0.8692 - val_loss: 0.3454 - val_accuracy: 0.8576\n",
      "Epoch 9/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2918 - accuracy: 0.8774\n",
      "Epoch 00009: val_accuracy did not improve from 0.86024\n",
      "28/28 [==============================] - 26s 928ms/step - loss: 0.2945 - accuracy: 0.8745 - val_loss: 0.3559 - val_accuracy: 0.8559\n",
      "Epoch 10/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2950 - accuracy: 0.8695\n",
      "Epoch 00010: val_accuracy improved from 0.86024 to 0.86111, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 26s 932ms/step - loss: 0.2965 - accuracy: 0.8692 - val_loss: 0.3489 - val_accuracy: 0.8611\n",
      "Epoch 11/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2869 - accuracy: 0.8797\n",
      "Epoch 00011: val_accuracy did not improve from 0.86111\n",
      "28/28 [==============================] - 26s 921ms/step - loss: 0.2863 - accuracy: 0.8796 - val_loss: 0.3516 - val_accuracy: 0.8550\n",
      "Epoch 12/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2959 - accuracy: 0.8774\n",
      "Epoch 00012: val_accuracy improved from 0.86111 to 0.86198, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 26s 928ms/step - loss: 0.2942 - accuracy: 0.8787 - val_loss: 0.3392 - val_accuracy: 0.8620\n",
      "Epoch 13/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3056 - accuracy: 0.8561\n",
      "Epoch 00013: val_accuracy did not improve from 0.86198\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 0.3021 - accuracy: 0.8585 - val_loss: 0.3540 - val_accuracy: 0.8446\n",
      "Epoch 14/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2855 - accuracy: 0.8757\n",
      "Epoch 00014: val_accuracy did not improve from 0.86198\n",
      "28/28 [==============================] - 26s 935ms/step - loss: 0.2835 - accuracy: 0.8779 - val_loss: 0.3819 - val_accuracy: 0.8455\n",
      "Epoch 15/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2945 - accuracy: 0.8698\n",
      "Epoch 00015: val_accuracy did not improve from 0.86198\n",
      "28/28 [==============================] - 26s 936ms/step - loss: 0.3006 - accuracy: 0.8638 - val_loss: 0.3639 - val_accuracy: 0.8429\n",
      "Epoch 16/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2970 - accuracy: 0.8777\n",
      "Epoch 00016: val_accuracy did not improve from 0.86198\n",
      "28/28 [==============================] - 26s 940ms/step - loss: 0.2991 - accuracy: 0.8754 - val_loss: 0.3730 - val_accuracy: 0.8507\n",
      "Epoch 17/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.3031 - accuracy: 0.8666\n",
      "Epoch 00017: val_accuracy did not improve from 0.86198\n",
      "28/28 [==============================] - 26s 944ms/step - loss: 0.3028 - accuracy: 0.8675 - val_loss: 0.3455 - val_accuracy: 0.8550\n",
      "Epoch 18/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2990 - accuracy: 0.8684\n",
      "Epoch 00018: val_accuracy did not improve from 0.86198\n",
      "28/28 [==============================] - 27s 970ms/step - loss: 0.2989 - accuracy: 0.8692 - val_loss: 0.3483 - val_accuracy: 0.8611\n",
      "Epoch 19/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2892 - accuracy: 0.8797\n",
      "Epoch 00019: val_accuracy did not improve from 0.86198\n",
      "28/28 [==============================] - 28s 1s/step - loss: 0.2931 - accuracy: 0.8754 - val_loss: 0.3431 - val_accuracy: 0.8602\n",
      "Epoch 20/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2825 - accuracy: 0.8754\n",
      "Epoch 00020: val_accuracy improved from 0.86198 to 0.86719, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 25s 909ms/step - loss: 0.2860 - accuracy: 0.8742 - val_loss: 0.3349 - val_accuracy: 0.8672\n",
      "Epoch 21/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2944 - accuracy: 0.8722\n",
      "Epoch 00021: val_accuracy did not improve from 0.86719\n",
      "28/28 [==============================] - 26s 932ms/step - loss: 0.2951 - accuracy: 0.8706 - val_loss: 0.3614 - val_accuracy: 0.8455\n",
      "Epoch 22/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2844 - accuracy: 0.8806\n",
      "Epoch 00022: val_accuracy did not improve from 0.86719\n",
      "28/28 [==============================] - 28s 994ms/step - loss: 0.2859 - accuracy: 0.8796 - val_loss: 0.3474 - val_accuracy: 0.8594\n",
      "Epoch 23/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2946 - accuracy: 0.8701\n",
      "Epoch 00023: val_accuracy did not improve from 0.86719\n",
      "28/28 [==============================] - 25s 901ms/step - loss: 0.2947 - accuracy: 0.8700 - val_loss: 0.3351 - val_accuracy: 0.8646\n",
      "Epoch 24/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2916 - accuracy: 0.8777\n",
      "Epoch 00024: val_accuracy did not improve from 0.86719\n",
      "28/28 [==============================] - 26s 913ms/step - loss: 0.2882 - accuracy: 0.8804 - val_loss: 0.3390 - val_accuracy: 0.8611\n",
      "Epoch 25/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2849 - accuracy: 0.8759\n",
      "Epoch 00025: val_accuracy did not improve from 0.86719\n",
      "28/28 [==============================] - 25s 899ms/step - loss: 0.2844 - accuracy: 0.8756 - val_loss: 0.3361 - val_accuracy: 0.8559\n",
      "Epoch 26/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2973 - accuracy: 0.8733\n",
      "Epoch 00026: val_accuracy did not improve from 0.86719\n",
      "28/28 [==============================] - 25s 898ms/step - loss: 0.2941 - accuracy: 0.8739 - val_loss: 0.3625 - val_accuracy: 0.8576\n",
      "Epoch 27/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2940 - accuracy: 0.8747\n",
      "Epoch 00027: val_accuracy did not improve from 0.86719\n",
      "28/28 [==============================] - 25s 904ms/step - loss: 0.2953 - accuracy: 0.8739 - val_loss: 0.3611 - val_accuracy: 0.8524\n",
      "Epoch 28/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2713 - accuracy: 0.8873\n",
      "Epoch 00028: val_accuracy improved from 0.86719 to 0.86892, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 25s 905ms/step - loss: 0.2741 - accuracy: 0.8852 - val_loss: 0.3334 - val_accuracy: 0.8689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2731 - accuracy: 0.8835\n",
      "Epoch 00029: val_accuracy did not improve from 0.86892\n",
      "28/28 [==============================] - 25s 895ms/step - loss: 0.2733 - accuracy: 0.8821 - val_loss: 0.3402 - val_accuracy: 0.8602\n",
      "Epoch 30/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2751 - accuracy: 0.8867\n",
      "Epoch 00030: val_accuracy did not improve from 0.86892\n",
      "28/28 [==============================] - 25s 905ms/step - loss: 0.2777 - accuracy: 0.8841 - val_loss: 0.3416 - val_accuracy: 0.8576\n",
      "Epoch 31/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2660 - accuracy: 0.8955\n",
      "Epoch 00031: val_accuracy did not improve from 0.86892\n",
      "28/28 [==============================] - 25s 899ms/step - loss: 0.2690 - accuracy: 0.8928 - val_loss: 0.3408 - val_accuracy: 0.8628\n",
      "Epoch 32/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2847 - accuracy: 0.8710\n",
      "Epoch 00032: val_accuracy did not improve from 0.86892\n",
      "28/28 [==============================] - 25s 901ms/step - loss: 0.2869 - accuracy: 0.8700 - val_loss: 0.3639 - val_accuracy: 0.8455\n",
      "Epoch 33/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2907 - accuracy: 0.8634\n",
      "Epoch 00033: val_accuracy improved from 0.86892 to 0.86979, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 25s 903ms/step - loss: 0.2899 - accuracy: 0.8633 - val_loss: 0.3444 - val_accuracy: 0.8698\n",
      "Epoch 34/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2861 - accuracy: 0.8757\n",
      "Epoch 00034: val_accuracy did not improve from 0.86979\n",
      "28/28 [==============================] - 25s 892ms/step - loss: 0.2842 - accuracy: 0.8762 - val_loss: 0.3620 - val_accuracy: 0.8516\n",
      "Epoch 35/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2872 - accuracy: 0.8736\n",
      "Epoch 00035: val_accuracy did not improve from 0.86979\n",
      "28/28 [==============================] - 25s 903ms/step - loss: 0.2876 - accuracy: 0.8747 - val_loss: 0.3446 - val_accuracy: 0.8637\n",
      "Epoch 36/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2867 - accuracy: 0.8806\n",
      "Epoch 00036: val_accuracy did not improve from 0.86979\n",
      "28/28 [==============================] - 25s 906ms/step - loss: 0.2826 - accuracy: 0.8827 - val_loss: 0.3393 - val_accuracy: 0.8681\n",
      "Epoch 37/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2704 - accuracy: 0.8824\n",
      "Epoch 00037: val_accuracy improved from 0.86979 to 0.88281, saving model to 0422_binary_test1.h5\n",
      "28/28 [==============================] - 25s 904ms/step - loss: 0.2721 - accuracy: 0.8810 - val_loss: 0.3258 - val_accuracy: 0.8828\n",
      "Epoch 38/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2764 - accuracy: 0.8908\n",
      "Epoch 00038: val_accuracy did not improve from 0.88281\n",
      "28/28 [==============================] - 25s 901ms/step - loss: 0.2781 - accuracy: 0.8880 - val_loss: 0.3490 - val_accuracy: 0.8655\n",
      "Epoch 39/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2804 - accuracy: 0.8765\n",
      "Epoch 00039: val_accuracy did not improve from 0.88281\n",
      "28/28 [==============================] - 25s 896ms/step - loss: 0.2791 - accuracy: 0.8776 - val_loss: 0.3506 - val_accuracy: 0.8611\n",
      "Epoch 40/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2738 - accuracy: 0.8838\n",
      "Epoch 00040: val_accuracy did not improve from 0.88281\n",
      "28/28 [==============================] - 25s 893ms/step - loss: 0.2712 - accuracy: 0.8846 - val_loss: 0.3312 - val_accuracy: 0.8689\n",
      "Epoch 41/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2703 - accuracy: 0.8870\n",
      "Epoch 00041: val_accuracy did not improve from 0.88281\n",
      "28/28 [==============================] - 27s 954ms/step - loss: 0.2683 - accuracy: 0.8883 - val_loss: 0.3401 - val_accuracy: 0.8594\n",
      "Epoch 42/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2768 - accuracy: 0.8815\n",
      "Epoch 00042: val_accuracy did not improve from 0.88281\n",
      "28/28 [==============================] - 32s 1s/step - loss: 0.2792 - accuracy: 0.8818 - val_loss: 0.3750 - val_accuracy: 0.8394\n",
      "Epoch 43/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2745 - accuracy: 0.8789\n",
      "Epoch 00043: val_accuracy did not improve from 0.88281\n",
      "28/28 [==============================] - 25s 900ms/step - loss: 0.2773 - accuracy: 0.8770 - val_loss: 0.3357 - val_accuracy: 0.8576\n",
      "Epoch 44/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2890 - accuracy: 0.8666\n",
      "Epoch 00044: val_accuracy did not improve from 0.88281\n",
      "28/28 [==============================] - 25s 904ms/step - loss: 0.2869 - accuracy: 0.8669 - val_loss: 0.3566 - val_accuracy: 0.8542\n",
      "Epoch 45/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2683 - accuracy: 0.8862\n",
      "Epoch 00045: val_accuracy did not improve from 0.88281\n",
      "28/28 [==============================] - 28s 1s/step - loss: 0.2721 - accuracy: 0.8824 - val_loss: 0.3433 - val_accuracy: 0.8481\n",
      "Epoch 46/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2846 - accuracy: 0.8847\n",
      "Epoch 00046: val_accuracy did not improve from 0.88281\n",
      "28/28 [==============================] - 27s 954ms/step - loss: 0.2820 - accuracy: 0.8855 - val_loss: 0.3239 - val_accuracy: 0.8672\n",
      "Epoch 47/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2702 - accuracy: 0.8830\n",
      "Epoch 00047: val_accuracy did not improve from 0.88281\n",
      "28/28 [==============================] - 24s 856ms/step - loss: 0.2692 - accuracy: 0.8832 - val_loss: 0.3354 - val_accuracy: 0.8724\n",
      "Epoch 48/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2589 - accuracy: 0.8911\n",
      "Epoch 00048: val_accuracy did not improve from 0.88281\n",
      "28/28 [==============================] - 24s 868ms/step - loss: 0.2597 - accuracy: 0.8917 - val_loss: 0.3387 - val_accuracy: 0.8594\n",
      "Epoch 49/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2624 - accuracy: 0.8940\n",
      "Epoch 00049: val_accuracy did not improve from 0.88281\n",
      "28/28 [==============================] - 25s 885ms/step - loss: 0.2638 - accuracy: 0.8920 - val_loss: 0.3448 - val_accuracy: 0.8585\n",
      "Epoch 50/50\n",
      "27/28 [===========================>..] - ETA: 0s - loss: 0.2940 - accuracy: 0.8684\n",
      "Epoch 00050: val_accuracy did not improve from 0.88281\n",
      "28/28 [==============================] - 25s 896ms/step - loss: 0.2924 - accuracy: 0.8692 - val_loss: 0.3634 - val_accuracy: 0.8559\n"
     ]
    }
   ],
   "source": [
    "H = model.fit_generator(train_generator, steps_per_epoch=len(trainX)//batchsize,\n",
    "              validation_data=val_generator, validation_steps=len(valX)//batchsize,\n",
    "              epochs=epoch_num, verbose=1, callbacks=[checkpoint,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "N = epoch_num\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"crack-noncrack(VGG)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"0422_binary_test1.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.predict(testX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = NUM_EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "#plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"ResNet:Training Loss and Accuracy on crack damage level\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"Resnet_plot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
