{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from imutils.paths import list_images\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pv_vision.nn import ModelHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will put this method into util in the future\n",
    "class SolarDataset(VisionDataset):\n",
    "    \"\"\"A dataset directly read images and masks from folder.    \n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 root, \n",
    "                 image_folder, \n",
    "                 mask_folder,\n",
    "                 transforms,\n",
    "                 mode = \"train\",\n",
    "                 random_seed=42):\n",
    "        super().__init__(root, transforms)\n",
    "        self.image_path = Path(self.root) / image_folder\n",
    "        self.mask_path = Path(self.root) / mask_folder\n",
    "\n",
    "        if not os.path.exists(self.image_path):\n",
    "            raise OSError(f\"{self.image_path} not found.\")\n",
    "\n",
    "        if not os.path.exists(self.mask_path):\n",
    "            raise OSError(f\"{self.mask_path} not found.\")\n",
    "\n",
    "        self.image_list = sorted(list(list_images(self.image_path)))\n",
    "        self.mask_list = sorted(list(list_images(self.mask_path)))\n",
    "\n",
    "        self.image_list = np.array(self.image_list)\n",
    "        self.mask_list = np.array(self.mask_list)\n",
    "\n",
    "        np.random.seed(random_seed)\n",
    "        index = np.arange(len(self.image_list))\n",
    "        np.random.shuffle(index)\n",
    "        self.image_list = self.image_list[index]\n",
    "        self.mask_list = self.mask_list[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getname__(self, index):\n",
    "        image_name = os.path.splitext(os.path.split(self.image_list[index])[-1])[0]\n",
    "        mask_name = os.path.splitext(os.path.split(self.mask_list[index])[-1])[0]\n",
    "\n",
    "        if image_name == mask_name:\n",
    "            return image_name\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if not self.__getname__(index):\n",
    "            raise ValueError(\"{}: Image doesn't match with mask\".format(os.path.split(self.image_list[index])[-1]))\n",
    "        image = Image.open(self.image_list[index])\n",
    "        mask = Image.open(self.mask_list[index]).convert('L')\n",
    "        mask = np.array(mask)\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        image, mask = self.transforms(image, mask)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will put into utils in the future\n",
    "class Compose:\n",
    "    def __init__(self, transforms):\n",
    "        \"\"\"\n",
    "        transforms: a list of transform\n",
    "        \"\"\"\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __call__(self, image, target):\n",
    "        \"\"\"\n",
    "        image: input image\n",
    "        target: input mask\n",
    "        \"\"\"\n",
    "        for t in self.transforms:\n",
    "            image, target = t(image, target)\n",
    "        return image, target\n",
    "\n",
    "class FixResize:\n",
    "    # UNet requires input size to be multiple of 16\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, image, target):\n",
    "        image = F.resize(image, (self.size, self.size), interpolation=transforms.InterpolationMode.BILINEAR)\n",
    "        target = F.resize(target, (self.size, self.size), interpolation=transforms.InterpolationMode.NEAREST)\n",
    "        return image, target\n",
    "\n",
    "class ToTensor:\n",
    "    \"\"\"Transform the image to tensor. Scale the image to [0,1] float32.\n",
    "    Transform the mask to tensor.\n",
    "    \"\"\"\n",
    "    def __call__(self, image, target):\n",
    "        image = transforms.ToTensor()(image)\n",
    "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
    "        return image, target\n",
    "\n",
    "class PILToTensor:\n",
    "    \"\"\"Transform the image to tensor. Keep raw type.\"\"\"\n",
    "    def __call__(self, image, target):\n",
    "        image = F.pil_to_tensor(image)\n",
    "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
    "        return image, target\n",
    "\n",
    "class Normalize:\n",
    "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, image, target):\n",
    "        image = F.normalize(image, mean=self.mean, std=self.std)\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The images and lables are only for tutorial demosntration.\n",
    "# The complete data set we used for model development can be found here:\n",
    "# https://datahub.duramat.org/dataset/00b29daf-239c-47b6-bd96-bfb0875179a8/resource/5e9d5503-cb2f-42b7-be5a-282514c60f39/download/train_val_upsample_aug.zip\n",
    "\n",
    "root = Path('../examples/crack_segmentation/img_label_for_training')\n",
    "transformers = Compose([FixResize(256), ToTensor(), Normalize()])\n",
    "\n",
    "trainset = SolarDataset(root, image_folder=\"train/img\", \n",
    "        mask_folder=\"train/ann\", transforms=transformers)\n",
    "\n",
    "valset = SolarDataset(root, image_folder=\"val/img\", \n",
    "        mask_folder=\"val/ann\", transforms=transformers)\n",
    "\n",
    "testset = SolarDataset(root, image_folder=\"testset/img\", \n",
    "        mask_folder=\"testset/ann\", transforms=transformers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeepLab_pretrained(num_classes):\n",
    "    deeplab = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
    "    deeplab.classifier = DeepLabHead(2048, num_classes)\n",
    "    return deeplab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DataParallel(DeepLab_pretrained(5))\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.01)\n",
    "lr_scheduler = StepLR(optimizer, step_size=5, gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize modelhandler\n",
    "# The output is stored in the output folder\n",
    "modelhandler = ModelHandler(\n",
    "    model=model,\n",
    "    model_output='out',\n",
    "    train_dataset=trainset,\n",
    "    val_dataset=valset,\n",
    "    test_dataset=testset,\n",
    "    batch_size_train=32,\n",
    "    batch_size_val=32,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    num_epochs=10,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    save_dir='checkpoints',\n",
    "    save_name='deeplab.pt'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [01:16<00:00,  2.45s/it]\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4173 (train) | 4.9578 (val)\n",
      "Epoch 2 / 10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [01:17<00:00,  2.48s/it]\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1789 (train) | 0.1916 (val)\n",
      "Epoch 3 / 10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [01:18<00:00,  2.53s/it]\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1192 (train) | 0.1170 (val)\n",
      "Epoch 4 / 10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [01:19<00:00,  2.57s/it]\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1049 (train) | 0.1077 (val)\n",
      "Epoch 5 / 10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [01:19<00:00,  2.57s/it]\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0942 (train) | 0.0964 (val)\n",
      "Epoch 6 / 10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [01:19<00:00,  2.58s/it]\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0882 (train) | 0.0882 (val)\n",
      "Epoch 7 / 10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [01:20<00:00,  2.58s/it]\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0849 (train) | 0.0861 (val)\n",
      "Epoch 8 / 10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [01:19<00:00,  2.58s/it]\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0839 (train) | 0.0836 (val)\n",
      "Epoch 9 / 10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [01:19<00:00,  2.57s/it]\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0826 (train) | 0.0833 (val)\n",
      "Epoch 10 / 10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [01:20<00:00,  2.58s/it]\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0800 (train) | 0.0824 (val)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': {'loss': [0.4173066987054338,\n",
       "   0.17885671862604197,\n",
       "   0.1192198520825233,\n",
       "   0.1049448441514753,\n",
       "   0.09418112763161522,\n",
       "   0.08817903688292444,\n",
       "   0.0848550075059565,\n",
       "   0.08386343555072698,\n",
       "   0.08257343704379144,\n",
       "   0.07998113717439244]},\n",
       " 'val': {'loss': [4.957792570424634,\n",
       "   0.19160857034284015,\n",
       "   0.11703312431657037,\n",
       "   0.10774861033572707,\n",
       "   0.09641222534484642,\n",
       "   0.08819531077562376,\n",
       "   0.08607308133396992,\n",
       "   0.08364118046538774,\n",
       "   0.08325028124936791,\n",
       "   0.08244443407585454]}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model. Note that this tutorial only runs 10 epochs. \n",
    "# It may take longer training iteration in real situation.\n",
    "modelhandler.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the minimum loss in validation, which is the best model\n",
    "np.argmin(modelhandler.running_record['val']['loss'])+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can load the best model and check its performance on testing set\n",
    "modelhandler.load_model('checkpoints/epoch_10/deeplab.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing mode\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:05<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.0780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_ = modelhandler.test_model()\n",
    "# Not bad. The testing score is similar to validation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-pv-vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
